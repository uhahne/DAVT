#### Termin

Mittwoch, 22.01.2025 in Raum L2.05a

### Ziele

- Grundprinzipien der KI Ansätze für Audio und Video
	- GAN
	- Stable Diffusion
- Beispiele
	- Synthesia


### Drehbuch

| Was                                  | Dauer  | Material                                                                                                                           |
| ------------------------------------ | ------ | ---------------------------------------------------------------------------------------------------------------------------------- |
| State of the art in video generation | 10 min | [Synthesia example](https://share.synthesia.io/25c894a3-e473-4f8f-8060-aa85f3b445bb)                                               |
| Generative Adverserial Networks      | 45 min | [[DAVT-10-KI.pdf]] bis Folie 17                                                                                                    |
| Audio Quiz                           | 5 min  | [Unofficial Parallel WaveGAN implementation demo](https://kan-bayashi.github.io/ParallelWaveGAN/)                                  |
| Stable Diffusion                     | 30 min | [[DAVT-10-KI.pdf]] und [The Illustrated Stable Diffusion by Jay Alammar](https://jalammar.github.io/illustrated-stable-diffusion/) |



#### Gezeigte Links

Die in den Unterlagen [[DAVT-10-KI.pdf]] verlinkten Seiten wurden gezeigt und besprochen. Darüber hinaus wurde kurz erläutert, was nvidia in ihrer [neuesten Grafikkartengeneration](https://nvidianews.nvidia.com/news/nvidia-blackwell-geforce-rtx-50-series-opens-new-world-of-ai-computer-graphics) anbietet: [DLSS4 mit Multi Frame Generation](https://www.nvidia.com/en-us/geforce/news/dlss4-multi-frame-generation-ai-innovations/)

#### Terminplanung


05.02. ab 14 Uhr Klausurvorbereitung im i0.15

07.02. 09:45-11:15 Uhr, Klausur (aka Modulprüfung Digitale Medienproduktion) Raum I0.14


### Was man verstanden haben sollte
- Ich habe eine grobe Vorstellung was ein GAN ist und weiß, welche Daten man benötigt um es zu trainieren.
- Ich habe verstanden, wie Stable Diffusion funktioniert.
- Ich habe gehört und gesehen, dass man inzwischen mit KI Methoden Audio- und Videodaten erzeugen kann, die von "echten" Aufnahmen nicht ohne Weiteres zu unterscheiden sind.